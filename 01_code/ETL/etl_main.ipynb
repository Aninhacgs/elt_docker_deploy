{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo parâmetros da chamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "headers = {'Cookie': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo url e enviando chamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw = \"https://brasil.io/api/dataset/covid19/caso_full/data/?page=\"\n",
    "url_base = \"https://brasil.io/api/dataset/covid19/caso_full/data/?page=1\"\n",
    "response_url_base = requests.request(\"GET\", url_base, headers=headers, data = payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo diretório de trabalho e função nome diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR_PATH = os.getenv(\"RAW_DIR_PATH\", os.path.join(os.getcwd(), 'DataFrame', '01_RAW'))\n",
    "RAW_DIR = lambda x: os.path.join(RAW_DIR_PATH, re.sub('[^a-zA-Z0-9 \\n\\.]', '_', x + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o resultado da chamada\n",
    "##### A disponibilidade do link é sempre verificada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(response_url_base.text.encode('utf8').decode('utf8')) \\\n",
    "    if response_url_base.status_code == 200 \\\n",
    "        else print('Escrever Log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como há paginação da API e os dados crescem a cada dia, foi adicionado um um variável verificadora do link \"final\" da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://brasil.io/api/dataset/covid19/caso_full/data/?page=295\n"
     ]
    }
   ],
   "source": [
    "page_final = math.ceil(data['count']/len(data['results']))\n",
    "\n",
    "url_final = \"https://brasil.io/api/dataset/covid19/caso_full/data/?page=\" + str(page_final) + \"\"\n",
    "\n",
    "print(url_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://brasil.io/api/dataset/covid19/caso_full/data/?page=2', None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['next'], data['previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 'https://brasil.io/api/dataset/covid19/caso_full/data/?page=294')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_url_final = requests.request(\"GET\", url_final, headers=headers, data = payload)\n",
    "data_final = json.loads(response_url_final.text.encode('utf8').decode('utf8'))\n",
    "data_final['next'], data_final['previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o resultado da requisição em formato csv, na qual estava em formato json\n",
    "##### O arquivo apenas será salve caso ele não exista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame já carregado\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR_FILE = RAW_DIR(os.path.join(re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_base)))\n",
    "\n",
    "pd.DataFrame.from_dict(data['results'])\\\n",
    "    .to_csv(RAW_DIR_FILE, index = False) \\\n",
    "        if not re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_base) + '.csv' in os.listdir(RAW_DIR_PATH) \\\n",
    "            else  print('DataFrame já carregado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "Execução Terminada\n"
     ]
    }
   ],
   "source": [
    "link_num = 0\n",
    "link_num_begin = 80\n",
    "link_num_end = 90\n",
    "\n",
    "\n",
    "try:\n",
    "    while link_num_begin < link_num_end:\n",
    "        for link_num in range(link_num_begin, (link_num_end + 1)):\n",
    "\n",
    "            if re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_raw + str(link_num)) + '.csv' in os.listdir(RAW_DIR_PATH):\n",
    "                print('DataFrame já carregado', end = '\\n')\n",
    "            else:\n",
    "                response_url_link_num = requests.request(\"GET\", url_raw + str(link_num), headers=headers, data = payload)\n",
    "                data_link_num = json.loads(response_url_link_num.text.encode('utf8').decode('utf8')) if response_url_link_num.status_code == 200 else print('Escrever Log')\n",
    "\n",
    "                print(url_raw + str(link_num))\n",
    "\n",
    "                pd.DataFrame.from_dict(data_link_num['results'])\\\n",
    "                    .to_csv(RAW_DIR(url_raw + str(link_num)), index = False) \\\n",
    "                        if not re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_raw + str(link_num)) + '.csv' in os.listdir(RAW_DIR_PATH) else \\\n",
    "                            print('DataFrame já carregado', end = '\\n\\n')\n",
    "\n",
    "            link_num_begin = link_num_begin + 1\n",
    "\n",
    "            if link_num_begin == link_num_end:\n",
    "                break\n",
    "                \n",
    "except(TypeError, ConnectionError, JSONDecodeError, requests.exceptions.ConnectTimeout, HTTPError, ReadTimeout, Timeout, requests.exceptions.RequestException):\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    print('Execução Terminada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de uso tendo coomo base a url final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame já carregado\n",
      "DataFrame já carregado\n",
      "Execução Terminada\n"
     ]
    }
   ],
   "source": [
    "data_link = ''\n",
    "\n",
    "try:\n",
    "    while data_link != None:\n",
    "        for link_num in range(page_final - 1, page_final + 1):\n",
    "\n",
    "            if re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_raw + str(link_num)) + '.csv' in os.listdir(RAW_DIR_PATH):\n",
    "                print('DataFrame já carregado', end = '\\n')\n",
    "                \n",
    "                response_url_link_num = requests.request(\"GET\", url_raw + str(link_num), headers=headers, data = payload)\n",
    "                data_link_num = json.loads(response_url_link_num.text.encode('utf8').decode('utf8')) if response_url_link_num.status_code == 200 else print('Escrever Log')\n",
    "                data_link = data_link_num['next']\n",
    "                \n",
    "\n",
    "            else:\n",
    "                response_url_link_num = requests.request(\"GET\", url_raw + str(link_num), headers=headers, data = payload)\n",
    "                data_link_num = json.loads(response_url_link_num.text.encode('utf8').decode('utf8')) if response_url_link_num.status_code == 200 else print('Escrever Log')\n",
    "                data_link = data_link_num['next']\n",
    "                \n",
    "                print(url_raw + str(link_num))\n",
    "\n",
    "                pd.DataFrame.from_dict(data_link_num['results'])\\\n",
    "                    .to_csv(RAW_DIR(url_raw + str(link_num)) + '.csv', index = False) \\\n",
    "                        if not re.sub('[^a-zA-Z0-9 \\n\\.]', '_', url_raw + str(link_num)) + '.csv' in os.listdir(RAW_DIR_PATH) else \\\n",
    "                            print('DataFrame já carregado', end = '\\n\\n')\n",
    "\n",
    "\n",
    "                if data_link_num['next'] == None:\n",
    "                    break\n",
    "                \n",
    "except(TypeError, ConnectionError, JSONDecodeError, requests.exceptions.ConnectTimeout, HTTPError, ReadTimeout, Timeout, requests.exceptions.RequestException):\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    print('Execução Terminada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_link is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crição de uma lista ordenada dos arquivos csv salvos na raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = os.getcwd()\n",
    "#search_dir = os.getcwd() + '\\\\DataFrame\\\\01_raw'\n",
    "os.chdir(RAW_DIR_PATH)\n",
    "\n",
    "files = filter(os.path.isfile, os.listdir(RAW_DIR_PATH)) #selecionando apenas arquivos\n",
    "files = [os.path.join(RAW_DIR_PATH, f) for f in files] #adiciona o diretório completo em uma lista\n",
    "files.sort(key=lambda x: os.path.getmtime(x)) #ordernacao por ondem de data/hora\n",
    "files = [f.replace(RAW_DIR_PATH + os.path.sep, '') for f in files] #linux\n",
    "#files = [f.replace(RAW_DIR_PATH + '\\\\', '') for f in files] #windows\n",
    "\n",
    "os.chdir(maindir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda y: y.replace('.csv', '').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tabelas = {}\n",
    "\n",
    "for x in range(files.index(files[0]), (files.index(files[-1]) + 1)):\n",
    "\n",
    "    tabelas['' + files[x].replace('.csv', '') + ''] = pd.read_csv(RAW_DIR_PATH + os.path.sep + files[x], delimiter=',')\n",
    "\n",
    "files2order = [f.replace('.csv', '') for f in files]\n",
    "\n",
    "for key in files2order:\n",
    "    tabelas[key] = tabelas.pop(key)\n",
    "    \n",
    "for key_rename in list(tabelas):\n",
    "    tabelas[key_rename.replace('.', '_')] = tabelas.pop(key_rename)\n",
    "    \n",
    "locals().update(tabelas) #transformando valores do dicionário em variáveis locais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir por estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dash.plotly.com\n",
    "\n",
    "elt_main.py\n",
    "\n",
    "show_df.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
